---
title: "DS6373 Time Series Project"
author: "Paul Adams & Jeff Nguyen"
date: "3/6/2020"
output: 
    html_document:
      toc: TRUE
---

```{r soft infrastructure}
library(pacman)
p_load(tswge, dplyr, kableExtra, sqldf)
```

## Project Data

Data from this project was gathered using an API connection to the AlphaVantage server where all symbols listed on the NASDAQ were used to gather trade price and volume on daily intervals spanning the previous 100 days. Because it is expensive to trade intradaily, we're only considering daily data. Additionally important to note, due to the upcoming presedential election and coronavirus, which we expect to significantly confound correlations between lags in the realizations due to the stress on the global supply chain and the wide scope of industries likely to be impacted, we're focusing on data spanning from May 30th, 2019 through October 18th, 2019 (100 data points).

```#{r Data Selection, echo=FALSE}

files = list.files(path='../DatabaseProject/Stocks/NASDAQ_Daily', pattern='*.csv')
#files = list.files(path='../LoopTest', pattern='*.csv')

for(file in files){
  actualFile <- paste0('../DatabaseProject/Stocks/NASDAQ_Daily/',file)
  #actualFile <- paste0('../LoopTest/',file)
  df <- read.csv(actualFile)
  aicfive <- aic5.wge(df$low, type="bic") # bic because of its stinginess during variable selection

  if((aicfive$`   p`[1] < 3 && aicfive$`   q`[1] == 0 && abs(aicfive$`       bic`) < 3) | (aicfive$`   p`[2] < 3 && aicfive$`   q`[2] == 0 && abs(aicfive$`       bic`) < 3) | (aicfive$`   p`[3] < 3 && aicfive$`   q`[3] == 0 && abs(aicfive$`       bic`) < 3)){
    z <- data.frame(file, aicfive$`   p`, aicfive$`   q`, aicfive$`       bic`)
    z
    write.table(z, './z.csv', append=T)
  }
  
  #Sys.sleep(0.5)
}

x = acf(df2$low)
x$acf
# to look directly at what was selected:
df2 <- read.csv('../DatabaseProject/Stocks/NASDAQ_Daily/NASDAQ_Daily_AGND.csv', header=T)
aic5.wge(df2$low, type="bic")
plotts.sample.wge(df2$low, trunc = 75) # there is a significant peak at frequency 0.02


df2 <- read.csv('../Call_Center_Metrics_for_the_Health_Service_System.csv', header=T)
plotts.sample.wge(df2$Abandoned.Calls, trunc = 75)
x = acf(df2$Abandoned.Calls)
x$acf
pacf(df2$Abandoned.Calls)


plotts.sample.wge(df2$Average.Speed.of.Answer.in.Secs, trunc = 75)
x = acf(df2$Average.Speed.of.Answer.in.Secs)
x$acf
pacf(df2$Average.Speed.of.Answer.in.Secs) # AR(1)

# osciallatory pacfs and acfs indicate negative phis and thetas

aic5.wge(df2$Average.Speed.of.Answer.in.Secs)
aic5.wge(df2$Abandoned.Calls)
```

```#{r echo=T}
est.ar.wge(df2$Abandoned.Calls, type='mle', p=1)
est.arma.wge()
```


```#{r echo=T}
fore.arma.wge(df2$Abandoned.Calls, phi=0.2721913, n.ahead=30, lastn=T)
fore.aruma.wge(df2$Abandoned.Calls, phi=0.2721913, s=11, n.ahead=36, lastn=T)
fore.arma.wge()

# Model 1
phis=c(0.2721913)
thetas = 0

trainingSize = 70
horizon = 24
ASEHolder_1 = numeric()

for(i in 1:12)
{

  forecasts = fore.arma.wge(df2$Abandoned.Calls[i:(i + (trainingSize - 1))], phi=phis, theta=thetas, lastn=F, n.ahead=horizon, plot=F)

  forecasts = fore.aruma.wge(df2$Abandoned.Calls[i:(i + (trainingSize - 1))], phi=phis, theta=thetas, s=11, lastn=F, n.ahead=horizon, plot=F)
  ASE_1 = mean((df2$Abandoned.Calls[(trainingSize + i):(trainingSize + i + (horizon) - 1)] - forecasts$f)^2)
  
  
  ASEHolder_1[i] = ASE_1
  
}

WindowedASE_mod1 = mean(ASEHolder_1)

mod1_ASEs <- data.frame(ASEHolder_1)
mod1_windowase <- data.frame(WindowedASE_mod1)

colnames(mod1_ASEs) <- "Average Square Error Scores: Model 1"
colnames(mod1_windowase) <- "Windowed Average Square Error Score: Model 1"

kable(mod1_ASEs)
kable(mod1_windowase)

par(mfrow=c(2,2))
plot(df2$Abandoned.Calls,type = "l")
lines(df2$Abandoned.Calls,col = "blue", type = "l")
pacf(df2$Abandoned.Calls)
acf(df2$Abandoned.Calls)
parzen.wge(df2$Abandoned.Calls, trunc=45)
```

```{r Display Data, echo=T, warning=F, fig.width = 6, fig.asp = .84}
#par(mfrow=c(4,1))
par(mfrow=c(2,2))
plot(df2$low,type = "l")
lines(df2$low,col = "blue", type = "l")
pacf(df2$low)
acf(df2$low)
parzen.wge(df2$low, trunc=45)
```

```#{r Model Estimation, echo=T, warning=F}
est.arma.wge(df2$low)
est.ar.wge(df2$low)


fore.arma.wge(df2$low, phi=c(0.9256, -0.2137), theta=0, n.ahead=10, lastn=T, plot=T, limits=T)
 # based on the 12.5 decibel at frequency 0.02:
fore.aruma.wge(df2$low, phi=c(0.9256, -0.1137), s=12,  n.ahead=10, lastn=T, plot=T, limits=T)

artrans.wge(df2$low, phi.tr=2, plottr=T)
fore.aruma.wge(df2$low, phi=c(1.1256, -0.2137), s=12,  n.ahead=20, lastn=F)
fore.aruma.wge(df2$low, phi=c(1.1256, -0.2137), s=12,  n.ahead=30)
```

## Because no stocks in the first model provided stationary results, we are taking the first difference of all stocks and then assessing to identify realizations that offer a white noise ARMA(0,0) model post-first difference. We will then consider these models for direct analysis prior to forecasting. Once the model is stationary, we can estimate the white noise variance as the sample variance of the differenced data. White noise variance.

## we tried to avoid models that have low p,q models because of the risk of white noise presence, possibly driven by volatility in stocks such that estimating such a small model is likely to be influenced by white noise (which could correspond easily to a 0,0 model in a non-volatile industry).
For this reason, we searched for larger models that were among the lowest AIC scores produced by aci5.wge()

$\hat{\sigma}_a = sd(differenced model)^2$

```{r Data Selection - Alternative for Differencing, echo=FALSE}
#files = list.files(path='../Time-Series-Stocks', pattern='*.csv')
knitr::opts_chunk$set(echo=T)
knitr::opts_chunk$set(root.dir='C:/Users/Pablo/Desktop/z')

files = list.files(path='../TS6373/CUsersPabloDesktopDatabaseProjectStocksNASDAQ_Daily/NASDAQ_Daily', pattern='*.csv')

for(file in files){
  actualFile <- paste0('../TS6373/CUsersPabloDesktopDatabaseProjectStocksNASDAQ_Daily/NASDAQ_Daily/',file)

  df <- read.csv(actualFile)
  #newdf <- artrans.wge(df, phi.tr=1)
  if(plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[2]){ # to prevent wandering realizations, exclude a peak at 0
    
    aicfive <- aic5.wge(df$low, p=0:15, q=0:15, type="aic")
  
#    if((aicfive$`   p`[1] == 0 && aicfive$`   q`[1] == 0 && aicfive$`       aic` < 0) | (aicfive$`   p`[2] == 0 && aicfive$`   q`[2] == 0 && aicfive$`       aic` < 3) | (aicfive$`   p`[3] == 0 && aicfive$`   q`[3] == 0 && aicfive$`       aic` < 0)){
#      z <- data.frame(file, aicfive$`   p`, aicfive$`   q`, aicfive$`       aic`)
#      colnames(z) <- NULL
      #colnames(z) <- c("rank&stock","p","q","AIC")
      #z
#      write.table(z, './z.csv', append=T)
#    }
    
    if(aicfive$`       aic` < 0){
      y <- data.frame(file, aicfive$`   p`, aicfive$`   q`, aicfive$`       aic`)
      colnames(y) <- NULL
      write.table(y, './models_aic_less_than_0.csv', append=T)
    }
  }
#  Sys.sleep(0.5)
}

df_report <- read.csv('c:/users/pablo/desktop/ts6373/z.csv')

AIC_report <- sqldf("
select 
  r.stock
  , r.p
  , r.q
  , r.AIC
from df_report r
where r.AIC = (
  select max(f1.AIC) from df_report r1
  where r1.stock = r.stock
  and r1.p = r.p
  and r1.q = r.q
  and r1.AIC = r.AIC)")

df_arg <- df_arg[order(df_arg$AIC),]

data.frame(unique(df_arg$stock)) # c('CPTAG','CRWS','EXPCU','ITRM','PACQW','PXS','SSPK','YGYIP')

# to look directly at what was selected:
df_CPTAG <- read.csv('../DatabaseProject/Stocks/NASDAQ_Daily/NASDAQ_Daily_CPTAG.csv', header=T)
df_CPTAG <- data.frame(df_CPTAG$times, df_CPTAG$low)
colnames(df_CPTAG) <- c("times", "low")
plotts.sample.wge(df_CPTAG$low) # this is a weird one, but only extends beyond 95% limits in ACF roughly 5% of time so may be good.


#***********************************************************************************************************************
#********************************************* START-CRWS **************************************************************
#***********************************************************************************************************************

df_CRWS <- read.csv('../DatabaseProject/Stocks/NASDAQ_Daily/NASDAQ_Daily_CRWS.csv', header=T)
df_CRWS <- data.frame(df_CRWS$times, df_CRWS$low)
colnames(df_CRWS) <- c("times", "low")
plotts.sample.wge(df_CRWS$low) # Possibly prime candidate for d=1
x = artrans.wge(df_CRWS$low, phi.tr=1)
plotts.sample.wge(x) # 1/0.085 = periodic around 11.76 for differenced data
aic5.wge(x, type="aic")
est.x = est.arma.wge(y, p=4, q=1)
est.x
ljung.wge(est.x$res, p=4, q=1) # not enough info to indicate residuals are not white noise variance
ljung.wge(est.y$res, p=4, q=1, K=length(est.y)) # also confirms the unconditional residuals aren't NOT wnv

# n.ahead=12 for the 11.76 rounding to 12-day long period indicated from the differenced data's Parzen Window. Since the forecast is going to include that same difference, the frequency is derived from that differenced data's power spectrum.
fore.aruma.wge(df_CRWS$low, phi=c(2.05870679,-1.52979572,0.27701904,0.09827179), theta=c(0.6469453), d=1, n.ahead=12, lastn=T)

#***********************************************************************************************************************
#********************************************* EXIT-CRWS ***************************************************************
#***********************************************************************************************************************

df_EXPCU <- read.csv('../DatabaseProject/Stocks/NASDAQ_Daily/NASDAQ_Daily_EXPCU.csv', header=T)
df_EXPCU <- data.frame(df_EXPCU$times, df_EXPCU$low)
colnames(df_EXPCU) <- c("times", "low")
plotts.sample.wge(df_EXPCU$low) # this one maintains stationarity in the ACF and PACF plots, as well as spectral density, but the realization does not look repeatable.

df_ITRM <- read.csv('../DatabaseProject/Stocks/NASDAQ_Daily/NASDAQ_Daily_ITRM.csv', header=T)
df_ITRM <- data.frame(df_ITRM$times, df_ITRM$low)
colnames(df_ITRM) <- c("times", "low")
plotts.sample.wge(df_ITRM$low) # This one seems to go wandering
x = artrans.wge(df_ITRM$low, phi.tr=1)
plotts.sample.wge(x)

df_PACQW <- read.csv('../DatabaseProject/Stocks/NASDAQ_Daily/NASDAQ_Daily_PACQW.csv', header=T)
df_PACQW <- data.frame(df_PACQW$times, df_PACQW$low)
colnames(df_PACQW) <- c("times", "low")
plotts.sample.wge(df_PACQW$low) # This one is very similary to CPTAG, see CPTAG notes

df_PXS <- read.csv('../DatabaseProject/Stocks/NASDAQ_Daily/NASDAQ_Daily_PXS.csv', header=T)
df_PXS <- data.frame(df_PXS$times, df_PXS$low)
colnames(df_PXS) <- c("times", "low")
plotts.sample.wge(df_PXS$low) # This goes wandering, but based on the ACF could difference well
x = artrans.wge(df_PXS$low, phi.tr=1) # 1st difference
plotts.sample.wge(x) # 1st difference

df_SSPK <- read.csv('../DatabaseProject/Stocks/NASDAQ_Daily/NASDAQ_Daily_SSPK.csv', header=T)
df_SSPK <- data.frame(df_SSPK$times, df_SSPK$low)
colnames(df_SSPK) <- c("times", "low")
plotts.sample.wge(df_SSPK$low)

df_YGYIP <- read.csv('../DatabaseProject/Stocks/NASDAQ_Daily/NASDAQ_Daily_YGYIP.csv', header=T)
df_YGYIP <- data.frame(df_YGYIP$times, df_YGYIP$low)
colnames(df_YGYIP) <- c("times", "low")
plotts.sample.wge(df_YGYIP$low)

plotts.sample.wge(df2$low) # there is a significant peak at frequency 0.02; 1/0.02 = 50-day cycle

est.ar.wge(df2$low, p=1)

fore.aruma.wge(df2$low, phi=0.9310042, s=50, n.ahead=10, lastn=F)
```


```{r Finding Missing Values, Building the Time Scope, echo=T}
library(pacman)
p_load(WDI, dplyr, sqldf, tswge)

#WDIsearch("GDP")
#WDI(country = "US", indicator = "6.0.GDP_current")
#WDIsearch("military")
#WDI(indicator = "MS.MIL.XPND.CD")
GDP <- WDI(indicator="6.0.GDP_growth")
###############################################################################################
###############################################################################################
###############################################################################################

## Use indicator number to gather data
military <- WDI(indicator = "MS.MIL.XPND.CD") %>% data.frame()


colnames(military) <- c("iso2c", "country", "spend", "year")

# NOTE: there are 19 countries plus the EU in the G20. Get all years from the dataset where any G20 countries have nulls
dfInput <- sqldf("
  select * 
  from 
    (
     select *
     from military
     where country in ('Argentina', 'Australia', 'Brazil', 'Canada','China', 'France', 'Germany', 'India', 'Indonesia', 'Italy', 'Japan',                        'Korea, Rep.', 'Mexico', 'Russian Federation', 'Saudi Arabia', 'South Africa', 'Turkey', 'United Kingdom', 'United                         States','European Union')
     order by country asc
     )
  where spend is null order by year desc")

colnames(dfInput) <- c("iso2c", "country", "spend", "year")

# Generate a dataframe that has the min and max range of years where there are NAs. If there are too many years, we will need to impute or consider removing. This is essentially the check for missing values in our dataset. The goal is to derive a realization for a timeframe we can model without needing to impute. Because the scale and range of time in this dataset -  59 discrete intervals spanning 59 years - imputations can prevent valid forecasting.

for(country in dfInput$country){
  timeframe <- sqldf("
  select case when min <= 1993 then 1993 -- 1993 b/c this is when this info was recorded for Russia (no longer USsR)
              when min = 2019 then 1993 else min end as min -- for countries that reported all, 2019 is the only NA
         , case when max = min then 2019 else max end as max
         , country
  from (select max(year) as max, min(year) as min, country from dfInput group by country)
  order by country asc, min asc, max desc")
}

df <- sqldf("select *
             from military
             where country in ('Argentina', 'Australia', 'Brazil', 'Canada','China', 'France', 'Germany', 'India', 'Indonesia', 'Italy',                                 'Japan','Korea, Rep.', 'Mexico', 'Russian Federation', 'Saudi Arabia', 'South Africa', 'Turkey', 'United                                   Kingdom', 'United States','European Union')
             and year between 1993 and 2018
             order by country asc")

df2 <- sqldf("select year, spend
             from military
             where country in ('Argentina', 'Australia', 'Brazil', 'Canada','China', 'France', 'Germany', 'India', 'Indonesia', 'Italy',                                 'Japan','Korea, Rep.', 'Mexico', 'Russian Federation', 'Saudi Arabia', 'South Africa', 'Turkey', 'United                                   Kingdom', 'United States','European Union')
             and year between 1993 and 2018
             group by year, spend
             order by year asc")

df3 <- sqldf("select year, spend
             from military
             where country in ('Argentina', 'Australia', 'Brazil', 'Canada','China', 'France', 'Germany', 'India', 'Indonesia', 'Italy',                                 'Japan','Korea, Rep.', 'Mexico', 'Russian Federation', 'Saudi Arabia', 'South Africa', 'Turkey', 'United                                   Kingdom', 'United States','European Union')
             and year between 1993 and 2018
             group by year
             order by year asc")
     
timeframe
```




```{r echo=T, warnings=F}
df2$spend <- df2$spend/1000000000 # convert to billions for simpler model - also, aic5 doesn't like these massive numbers
df3$spend <- df3$spend/1000000000

# It is important to note that because there are multiple countries for each time interval, this is an ensemble model. Potentially up to nine periods exist in the  spectral density window. However, when looking at the realization, this does not 
plotts.sample.wge(df3$spend)

# The composite realization (non-endemble) produces wandering behavior, supported by the peak at 0 in the power spectrum. For that reason, a non-stationary ARIMA(p,d,q) might be the best model to use. Using point 128, the frequency of 0.259109312 produces a period of roughly 3.859 years. This will be the first attempt for seasonality.
df2a <- df2
plotts.sample.wge(df2$spend)
factor.wge(phi=c(rep(0,3),1)) # (1 / 0.259109312) = 3.859, rounding to a period of 4 as the most infrequent
df2a.mod <- artrans.wge(df2$spend, phi.tr=c(rep(0,3),1))
plotts.sample.wge(df2a.mod)
df2a.mod1 <- artrans.wge(df2a.mod, phi.tr=2)
pacf(df2a.mod1)


r = artrans.wge(df3$spend, phi.tr=1)
plotts.sample.wge(r)

plotts.sample.wge(df3$spend)

# by looking at the PACF, there is extremely significant autocorrelation at around lags 18-20, corresponding to 2011, 2012, and 2013 where spending decreased (positive autocorrelation for years 2011 and 2012 and negative autocorrelation for 2013, where spending increased in the 20th lag, respective of the 19th lag).
pacf(df2$spend) # This shows AR(p). As much as an AR(4) or AR(5) component will likely be needed.

# in looking at the ACF, it looks like there is a periodic cycle completing every 18-20 years where spending slowly increases for about 18 years, then decreases rapidly for roughly three years before decreasing slowly over another 18-year period.
acf(df2$spend) # This shows MA(q). Up to potentially and MA(5) could be useful.

# running model identification (finding p and q) for the ensemble
y_ensemble <- aic5.wge(df2$spend, p=0:15, q=0:15, type="aic")
z_ensemble <- aic5.wge(df2$spend, p=0:15, q=0:15, type="bic")

y_ensemble <- data.frame(y_ensemble$`       aic`, y_ensemble$`   p`, y_ensemble$`   q`)
z_ensemble <- data.frame(z_ensemble$`       bic`, z_ensemble$`   p`, z_ensemble$`   q`)

x_ensemble <- data.frame(y_ensemble, z_ensemble)
colnames(x_ensemble) <- c("AIC Score", "p (AIC)", "q (AIC)", "BIC Score", "p (BIC)", "q (BIC)")

kable(x_ensemble) # Both BIC and AIC suggest and ARMA(1, 13) is best.

# running model identification (finding p and q) for the composite realization
y_realization <- aic5.wge(df3$spend, p=0:15, q=0:15, type="aic") # the result for BIC was AR(2), but for AIC AR(13). Going to re-asess
z_realization <- aic5.wge(df3$spend, p=0:15, q=0:15, type="bic")

y_realization <- data.frame(y_realization$`       aic`, y_realization$`   p`, y_realization$`   q`)
z_realization <- data.frame(z_realization$`       bic`, z_realization$`   p`, z_realization$`   q`)

x_realization <- data.frame(y_realization, z_realization)
colnames(x_realization) <- c("AIC Score", "p (AIC)", "q (AIC)", "BIC Score", "p (BIC)", "q (BIC)")

kable(x_realization) # Both BIC and AIC suggest and ARMA(1, 13) is best.

y_realization2 <- aic5.wge(df3$spend, p=0:5, q=0:5, type="aic") # this provided an AIC roughly 0.12 worse, but probably a better fit.
z_realization2 <- aic5.wge(df3$spend, p=0:5, q=0:5, type="bic")


y_realization2 <- data.frame(y_realization2$`       aic`, y_realization2$`   p`, y_realization2$`   q`)
z_realization2 <- data.frame(z_realization2$`       bic`, z_realization2$`   p`, z_realization2$`   q`)

x_realization2 <- data.frame(y_realization2, z_realization2)
colnames(x_realization2) <- c("AIC Score", "p (AIC)", "q (AIC)", "BIC Score", "p (BIC)", "q (BIC)")


est.ar.wge(df3$spend, p=15)
factor.wge(phi=c(rep(0,20),1))
est.ar.wge(df3$spend, p=3)

r_i <- fore.arma.wge(df3$spend, phi=c(2.0528996,-1.3549375,0.2821142), n.ahead=14, lastn=T)
```

```{r echo=T}
r_ii <- fore.arma.wge(df3$spend, phi=c(2.0528996,-1.3549375,0.2821142), n.ahead=5, lastn=T)
```

```{r echo=T}
r_iii <- fore.arma.wge(df3$spend, phi=c(2.0528996,-1.3549375,0.2821142), n.ahead=5, lastn=F)
```

```{r echo=T}
s_i <- fore.aruma.wge(df3$spend, phi=c(2.0528996,-1.3549375,0.2821142), s=21, n.ahead=55, lastn=F)
```

```{r echo=T}
s_ii <- fore.aruma.wge(df3$spend, phi=c(2.0528996,-1.3549375,0.2821142), s=21, n.ahead=15, lastn=F)
```

```
{r echo=T, warnings=F}
x <- artrans.wge(df$spend, phi.tr=1)
plotts.sample.wge(df2$spend)
pacf(x)
acf(x)

aic5.wge(x, p=0:5, q=0:5, type="aic")
# compare AIC to BIC:
aic5.wge(x, p=0:5, q=0:5, type="bic")

est.arma.wge(x, p=0, q=0)


```

