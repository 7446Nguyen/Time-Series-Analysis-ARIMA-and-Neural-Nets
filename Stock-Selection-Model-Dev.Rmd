---
title: "Stock-Selection-Analysis"
author: "Paul Adams & Jeff Nguyen"
date: "3/17/2020"
output: html_document
---

# Purpose
## This process provides a method to obtain stocks ideal for time series models such as AR, MA, ARMA, ARIMA, and Signal-Plus-Noiseide using the R package twsge.
```{r setup, include=FALSE}
library(pacman)
p_load(tswge, dplyr, kableExtra, sqldf, ggplot2, orcutt, tswgewrapped)
```

## Project Data Description

In this project, we analyze 3,202 stock price and volume data time series traded on the NASDAQ exchange between May 30th and October 30th, 2019. This date range was selected for its distance from significant biological and political disruption to the markets, which can both introduce artificial seasonality and increased random variation into forecasts. Data was sourced as comma-separated values through API from AlphaVantage.

Because of the time constraints involved with directly analyzing each stock, we developed a loop to process through each file, perform a brief assessment of the spectral density distribution to remove stocks with wandering behavior, defined by a peak at frequency zero. This was assessed by measuring if the first index of the Parzen Window is lower than any of the second through 17th indices. If not, the stock was discarded.

The methodology helped find stocks with seasonal components. We consider stationary seasonality to be an indication of a healthy company with long-term potential indicated by predictable behavior representing a balanced business process lifecycle. From that, we concluded if a company's stock performs in this way and the realization is positive, then it is a good stock for modeling.

Following the first-pass wandering analysis, all but 36 stocks remained, which we then analyzed directly using the parzen window's spectral density estimate, autocorrelation and partials autocorrelation plots and the realizations themselves. 

Once we obtained our chosen one, we estimated a model to fit it.
```{r cars}
files = list.files(path='../Time-Series-Stocks', pattern='*.csv')

for(file in files){
  actualFile <- paste0('../Time-Series-Stocks/',file)
  
  df <- read.csv(actualFile, header=T, strip.white=T)

  if(
    plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[2]|
    plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[3]|
    plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[4]|
    plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[5]|
    plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[6]|
    plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[7]|
    plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[8]|
    plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[9]|
    plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[10]|
    plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[11]|
    plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[12]|
    plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[13]|
    plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[14]|
    plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[15]|
    plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[16]|
    plotts.sample.wge(df$low)$dbz[1] < plotts.sample.wge(df$low)$dbz[17]
    ){
    
    aicfive <- aic5.wge(df$low, p=0:15, q=0:15, type="aic")

    if(aicfive$`       aic` < 0){
      y <- data.frame(file, aicfive$`   p`, aicfive$`   q`, aicfive$`       aic`)
      colnames(y) <- NULL
      write.table(y, './models_aic_less_than_0.csv', append=T)
    }
  }
#  Sys.sleep(0.15)
}
```

# This method uses linear regression to identify a profitable signal-plus-noise model fit. Cochran-orcutt is needed after selection of stocks.
```{r Signal Plus Noise, echo=T}
files = list.files(path='../Time-Series-Stocks', pattern='*.csv')

for(file in files){
  actualFile <- paste0('../Time-Series-Stocks/',file)
  
  df <- read.csv(actualFile, header=T, strip.white=T)

  # run linear regression to get the signal (average).
  t = seq(1, nrow(df),1)
  fit = lm(df$low~t)
  
  # get the frequency values from the spectral density in the Parzen Window (we want them to wander without season; just trend)
  dbz <- plotts.sample.wge(df$low)[4] # plotting sample plots to see the stocks while they process

  # if the linear coefficient (deterministic signal) for the price is positive and the price is between 5 and 50 (affordable):
  if(fit$coefficients[2] > 0.04 && df$low[nrow(df)] > 5 && df$low[nrow(df)] < 50){
    for(i in 1:(length(dbz$dbz)-1)){
      # if the realization is wandering (based on spectral density):
      if(dbz$dbz[i] > dbz$dbz[i+1]){
        write.table(df$symbol, './models_aic_less_than_0.csv', append=T)
      }
    }
  }
}

```

## This is most likely not useful:
```{r pressure, echo=FALSE}
df <- read.csv('./NASDAQ_Daily_ACGL.csv', header=T, strip.white=F)
plotts.sample.wge(df$low, arlimits=T)

############## sandbox
############## sandbox
############## sandbox
############## sandbox

aic5.wge(df$low, type="aic")
df.r = est.arma.wge(df$low, p=5) # dominant factor is a (1-B) so we need to difference the data
# (1-1.0272B+0.5751B^2)(1+0.8350B+0.3648B^2) => (0.20979648B^4 + 0.10548594B^3 + 0.082188B^2 - 0.1922B + 1)X_t = a_t

plotts.sample.wge(df.r$res, arlimits=T)
ljung.wge(df.r$res, p=5) # p-value is not significant so we do not reject the null. The autocorrelations are likely white noise for all t.
ljung.wge(df.r$res, p=5, K=48) # the p-value remains above the level of significance.

plotts.true.wge(phi=df.r$phi) # the spectral density of both the residuals and the actuals have wandering peaks. We apply an
plotts.sample.wge(df$low) # ARUMA(5,1,)

############## sandbox
############## sandbox
############## sandbox
############## sandbox


t = seq(1, nrow(df),1)
fit = lm(df$low~t)
# there is deterministic trend; the p-value is significant so reject the null that it is not deterministic. The null argues
# that any trend is random. The alternative argues that the trend is deterministic. Here, we reject the null:
summary(fit)
cfit = cochrane.orcutt(fit) # to confirm with chochrane-orcutt
summary(cfit) # Cochran-Orcutt also provides a significant p-value

# Because the model is confirmed to have a deterministic trend, we will forecast with a signal-plus-noise model
# Now, we need to analyze the residuals to determine if our
x.z = fit$residuals # residuals from the noise component
ar.z = aic5.wge(x.z, p=0:7, q=0, type="aic") # identify a model from the residuals; because we can only forecast sigplusnoise with AR(p), no q measured. Also confirmed, aic and bic both pick an AR(2) model as the best AR(p)
plotts.sample.wge(x.z) # the spectral density of the residuals matches that of the original distribution
lines(x.z,col = "blue", type = "l")
test = artrans.wge(x.z, phi.tr=1)
plotts.sample.wge(test, arlimits=T)


# mle because it produces stationary and non-stationary models.
est.ar.wge(df$low, p=12, type="mle") # we have one dominant (1-B) in the original data so we take a first difference to remove the trend
new_df <- artrans.wge(df$low, phi.tr=1) # trend has been removed
plotts.sample.wge(new_df)

model_bic <- aic5.wge(new_df, type="bic")
final_model_bic <- est.arma.wge(new_df, p=model_bic$`   p`[1], q=model_bic$`   q`[1])
fore.arma.wge(new_df, phi=final_model_bic$phi, theta=final_model_bic$theta, n.ahead=10, lastn=T, limits=T)


model_aic <- aic5.wge(new_df, type="aic")
final_model_aic <- est.arma.wge(new_df, p=model_aic$`   p`[1], q=model_aic$`   q`[1])
fore.arma.wge(df$low, phi=final_model_aic$phi, theta=final_model_aic$theta, n.ahead=10, lastn=T, limits=T)

x.trans = artrans.wge(df$low, phi.tr=ar.z$phi)
plotts.wge(x.trans) # visual of stationarity
lines(x.trans, col = "blue", type = "l")



x.trans = artrans.wge(x.z, phi.tr=ar.z$phi)
plotts.wge(x.trans) # visual of stationarity
lines(x.trans, col = "blue", type = "l")

model = est.ar.wge(x.trans, p=2, type="mle")
fore.arma.wge(z, phi=model$phi, n.ahead=12, lastn=T)
est.ar.wge(x.trans, p=12)
```


### Outline below is taken from the example using Hadley data from Unit 11 asynch. This signal plus noise should be good to go:
```{r echo=T}
df <- read.csv('./NASDAQ_Daily_ACGL.csv', header=T, strip.white=F)
plotts.sample.wge(df$low, arlimits=T)

####################
# Signal-Plus-Noise
####################
x = df$low
n = length(x)
t = 1:n
fit = lm(x ~ t)
summary(fit) # there appears to be deterministic trend based on OLS; the p-value is significant so reject the null that it is not deterministic. The null argues that any present trend is random that will eventually traverse such a pattern that the realization will continue to approximate around the mean. 

# Because OLS is not robust to non-stationarity, we apply the Cochrane-Orcutt test to also test the beta coefficient slope of time using an aproach that fits an AR(1) model to the residuals:
cfit = cochrane.orcutt(fit) # to confirm with chochrane-orcutt
summary(cfit) # Cochran-Orcutt also provides a significant p-value. Based on this, we assume the slope is not equal to zero and therefore, there is deterministic that justifies fitting a signal-plus-noise model instead of an ARMA(p,q). However, ARMA(p,q) will be fitted later for comparison.

#x.z = x - fit$coefficients[1] - fit$coefficients[2]*t # derive residuals
x.z = fit$residuals # derive residuals (from the regression line)
ar.z = aic.wge(x.z, p=0:6, type="aic") # find a model to use for approximating the residuals. NOTE: (sigmaHAT_a)^2 = 0.1177843
# ar.z$p is the order p (aic selects p=2 where q=0, as does the bic)

# Transform the stock prices by the autoregressive coefficients of the fitted residuals from the linear regression model
y.trans = artrans.wge(df$low, phi.tr=ar.z$phi)
# also, transform the predictor variable (time) by the autogregressive coefficeints of the fitted residuals as well
t.trans  = artrans.wge(t, phi.tr=ar.z$phi)
# Finally, regress the newly transformed stock prices (Y-HAT_t) on the transformed time (T-HAT_t)using ordinary least squares
fitco = lm(y.trans ~ t.trans)
summary(fitco) # check to see if the transformed beta coefficient for the slope is still significant

# Evaluating the residuals after Cochrane-Orcutt:
plotts.wge(fitco$residuals)
acf(fitco$residuals) # residuals appear to be white noise
ljung.wge(fitco$residuals) # there is not enough evidence based on the ljung-box test to reject the null hypothesis. Therefore, we cannot assume that the residuals are not white noise.

# Final Signal-Plus-Noise Model: X_t = 34.855438 + 0.072922*t + Z_t, (sigmaHAT_a)^2 = 0.1177843 summary(d = lm(x ~ t)) from hadley = a+bt
# creates the coefficients
ar.z$phi
# (1 - 1.0533533*B + 0.3193699*B^2)*Z_t = a__t. ar.z$phi from AR(2) creates the coeffients and (sigmaHAT_a)^2 = 0.1177843

# BUT, TO REITERATE: Final Signal-Plus-Noise Model is X_t = 34.855438 + 0.072922*t + Z_t, (sigmaHAT_a)^2 = 0.1177843
est_mod = gen.sigplusnoise.wge(100, b0=34.855438, b1 = 0.072922, phi=ar.z$phi, vara=0.1177843) # This is the estimated model in wge form
plotts.sample.wge(est_mod)
plotts.sample.wge(df$low) # the estimated model (above) matches to the actual model (here) on both ACFs and Spectral density as well as on partial ACF (below):
pacf(est_mod)
pacf(df$low)
fore.sigplusnoise.wge(df$low, max.p=2, n.ahead=10, limits=T, lastn=T, plot=T)
```


a### We take the signal, test the hypothesis of the presence of deterministic signal in the realization. Then, we separate the noise from the signal and estimate and ARMA/ARIMA model using differencing. We then take the model estimates and generate a signal pluse noise model forecast.

In the ARIMA model, we selected a forecast horizon of five trading days because this timeframe completes a full business week. Models can be fully re-developed on non-trading days. However, unless there are 2 unit roots, ARIMA will not forecast a trend to continue. Therefore, the forecast converge back toward the mean.


visual inspection of the spectral density estimate in the Parzen Window and the sample autocorrelations, it is apparent the data are wandering. Therefore, we decided to difference the data to add stationarity into the model.
```{r Seasonal ARIMA Model, echo=T, warning=F}
df <- read.csv('./NASDAQ_Daily_ACGL.csv', header=T, strip.white=F)
plotts.sample.wge(df$low, arlimits=T)
# factor.wge(df$low) # many unit roots in the data
noo_df <- artrans.wge(df$low, phi.tr=1)
parz <- plotts.sample.wge(noo_df)
noo_s <- round(1/parz$freq[which(parz$dbz == (max(parz$dbz)))], digits=0) # s=7
# Factor table for s=7:
aic5.wge(noo_df, type="aic") # aic picked an ARMA(5,1)
est.arma.wge(noo_df, p=13, q=1) # to over-fit the factor table, ARMA(10,2)
factor.wge(phi=c(rep(1,6),1))

est.arma.wge(noo_df, p=0, q=4) 
aic5.wge(noo_df, p=0:10, q=0:5) # because of complexity of model, AR(10) and MA(5)
est.arma.wge(noo_df, p=0, q=4)
noo_estimated <- est.arma.wge(noo_df, p=5, q=1)

# Comparing seasonal to non-seasonal model
seasonal.forecast <- fore.aruma.wge(df$low, theta=c(-0.05410508,0.16208339,0.21123368,0.40580505), d=1, s=7, n.ahead=15, lastn=T) #seasonal
nonseasonal.forecast <- fore.aruma.wge(df$low, theta=c(-0.05410508,0.16208339,0.21123368,0.40580505), d=1, n.ahead=5, lastn=T) # non-seasonal
plot(df$low, type="l")

tswgewrapped::ase(df$low, seasonal.forecast)
tswgewrapped::ase(df$low, nonseasonal.forecast)

```

```{r echo=T}

```
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
